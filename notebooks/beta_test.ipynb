{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4cb61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduar\\Documents\\usp\\AMST\\ml_timeseries_usp\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8412f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 21:16:45,499 - INFO - Config carregado de c:\\Users\\eduar\\Documents\\usp\\AMST\\ml_timeseries_usp\\config.yaml\n",
      "2025-12-02 21:16:46,322 - INFO - Config carregado de c:\\Users\\eduar\\Documents\\usp\\AMST\\ml_timeseries_usp\\config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Train: 2022-01-01 → 2025-01-01 (37 meses)\n",
      "Test (backtest): 2025-02-01 → 2025-07-01 (6 meses)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.data.make_dataset import DatasetCreator\n",
    "from src.data.make_hierarchical_dataset import DatasetHierarchicalAggregator\n",
    "from src.data.refine_dataset import HierarchicalTimeSeriesOutlierRemover\n",
    "from src.data.split import hierarchical_train_test_split\n",
    "from src.features.build_features import FeaturesBuilder\n",
    "from src.config import load_config\n",
    "from src.models.tuning import ModelTuning\n",
    "from src.models.train_model import CreateCanditateModel\n",
    "from src.evaluation.backtest_evaluation import ModelEvaluate,CompareRecMethods\n",
    "from src.data.back_to_origin import DatasetReconciliator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "config = load_config()\n",
    "\n",
    "if config['cache']:\n",
    "    print('loading data...')\n",
    "    df = DatasetCreator(config).load_intermediary()\n",
    "    Hagg = DatasetHierarchicalAggregator(config,df)\n",
    "    Y_df = Hagg.load_processed(filename='dataset.parquet')\n",
    "    S_df = Hagg.load_processed(filename='structure.parquet')\n",
    "    tags = Hagg.load_tags(filename='tags.joblib')\n",
    "    pass\n",
    "else:\n",
    "    df = DatasetCreator(config).run() \n",
    "\n",
    "    if config['exogen_features'] == 'true':\n",
    "        df = FeaturesBuilder(df,config).run()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    Y_df,S_df,tags = DatasetHierarchicalAggregator(config,df).run()\n",
    "\n",
    "train,test = hierarchical_train_test_split(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6913f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 21:17:55,583] A new study created in memory with name: no-name-56c19a81-220e-456b-b5a4-c9078abd6e79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'poisson', 'verbosity': -1, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-02 21:17:58,095] Trial 0 finished with value: 0.7283619200727317 and parameters: {'learning_rate': 0.03574712922600244, 'feature_fraction': 0.9852142919229748, 'bagging_fraction': 0.9195981825434215, 'lambda_l1': 0.0006155564318973012, 'lambda_l2': 1.77071686435378e-07, 'num_leaves': 16, 'max_depth': 3, 'min_data_in_leaf': 18, 'n_estimators': 1923}. Best is trial 0 with value: 0.7283619200727317.\n",
      "[I 2025-12-02 21:18:01,240] Trial 1 finished with value: 0.7806167286366525 and parameters: {'learning_rate': 0.11114989443094977, 'feature_fraction': 0.7061753482887407, 'bagging_fraction': 0.9909729556485982, 'lambda_l1': 0.04566054873446119, 'lambda_l2': 4.997040685255803e-07, 'num_leaves': 18, 'max_depth': 4, 'min_data_in_leaf': 9, 'n_estimators': 1717}. Best is trial 0 with value: 0.7283619200727317.\n",
      "[I 2025-12-02 21:18:03,420] Trial 2 finished with value: 0.7122282927919427 and parameters: {'learning_rate': 0.04345454109729477, 'feature_fraction': 0.7873687420594125, 'bagging_fraction': 0.8835558684167139, 'lambda_l1': 1.3060231803531604e-07, 'lambda_l2': 2.1734877073417355e-06, 'num_leaves': 28, 'max_depth': 6, 'min_data_in_leaf': 17, 'n_estimators': 839}. Best is trial 2 with value: 0.7122282927919427.\n",
      "[I 2025-12-02 21:18:06,839] Trial 3 finished with value: 0.7494635329426643 and parameters: {'learning_rate': 0.05748924681991978, 'feature_fraction': 0.8777243706586128, 'bagging_fraction': 0.7139351238159993, 'lambda_l1': 0.0007250347382396634, 'lambda_l2': 2.3130924416844053e-07, 'num_leaves': 11, 'max_depth': 10, 'min_data_in_leaf': 20, 'n_estimators': 2483}. Best is trial 2 with value: 0.7122282927919427.\n",
      "[I 2025-12-02 21:18:08,430] Trial 4 finished with value: 0.7157868903728248 and parameters: {'learning_rate': 0.028180680291847244, 'feature_fraction': 0.7293016342019151, 'bagging_fraction': 0.905269907953647, 'lambda_l1': 3.320625892007924e-05, 'lambda_l2': 9.469038421774442e-08, 'num_leaves': 36, 'max_depth': 3, 'min_data_in_leaf': 19, 'n_estimators': 998}. Best is trial 2 with value: 0.7122282927919427.\n",
      "[I 2025-12-02 21:18:13,792] Trial 5 pruned. \n",
      "[I 2025-12-02 21:18:16,230] Trial 6 pruned. \n",
      "[I 2025-12-02 21:18:17,989] Trial 7 finished with value: 0.7233836873145719 and parameters: {'learning_rate': 0.03364867144187954, 'feature_fraction': 0.7842803529062142, 'bagging_fraction': 0.8628088249474746, 'lambda_l1': 1.3408920002835378e-07, 'lambda_l2': 0.026156272064707428, 'num_leaves': 12, 'max_depth': 10, 'min_data_in_leaf': 17, 'n_estimators': 836}. Best is trial 2 with value: 0.7122282927919427.\n",
      "[I 2025-12-02 21:18:22,274] Trial 8 finished with value: 0.7198646792199194 and parameters: {'learning_rate': 0.010189592979395137, 'feature_fraction': 0.9446384285364502, 'bagging_fraction': 0.9120572031542851, 'lambda_l1': 0.006792933207180863, 'lambda_l2': 0.014796628616069285, 'num_leaves': 12, 'max_depth': 5, 'min_data_in_leaf': 6, 'n_estimators': 2631}. Best is trial 2 with value: 0.7122282927919427.\n",
      "[I 2025-12-02 21:18:24,683] Trial 9 pruned. \n",
      "[I 2025-12-02 21:18:24,966] Trial 10 pruned. \n",
      "[I 2025-12-02 21:18:26,662] Trial 11 finished with value: 0.7051123913640143 and parameters: {'learning_rate': 0.01821402716751085, 'feature_fraction': 0.7034572467435847, 'bagging_fraction': 0.9327155113866201, 'lambda_l1': 1.1028975146610365e-05, 'lambda_l2': 2.984352878369986e-05, 'num_leaves': 35, 'max_depth': 3, 'min_data_in_leaf': 15, 'n_estimators': 1039}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:29,339] Trial 12 finished with value: 0.7158346466673425 and parameters: {'learning_rate': 0.015576447513817237, 'feature_fraction': 0.7432273803164781, 'bagging_fraction': 0.9768897590917592, 'lambda_l1': 5.8284082195294306e-06, 'lambda_l2': 0.00011707166477225492, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 15, 'n_estimators': 1104}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:30,168] Trial 13 pruned. \n",
      "[I 2025-12-02 21:18:33,057] Trial 14 finished with value: 0.7095024734977029 and parameters: {'learning_rate': 0.010457065772553623, 'feature_fraction': 0.7601838544101867, 'bagging_fraction': 0.9503189177548766, 'lambda_l1': 1.1893683956151577e-08, 'lambda_l2': 0.0011185998282529114, 'num_leaves': 24, 'max_depth': 5, 'min_data_in_leaf': 16, 'n_estimators': 1341}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:35,460] Trial 15 finished with value: 0.7063865724242047 and parameters: {'learning_rate': 0.01047786389920168, 'feature_fraction': 0.703379749797706, 'bagging_fraction': 0.9420105848939073, 'lambda_l1': 1.2243723516524514e-08, 'lambda_l2': 0.0018577289982110118, 'num_leaves': 23, 'max_depth': 4, 'min_data_in_leaf': 12, 'n_estimators': 1371}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:37,357] Trial 16 pruned. \n",
      "[I 2025-12-02 21:18:38,355] Trial 17 pruned. \n",
      "[I 2025-12-02 21:18:38,983] Trial 18 pruned. \n",
      "[I 2025-12-02 21:18:39,395] Trial 19 pruned. \n",
      "[I 2025-12-02 21:18:40,819] Trial 20 pruned. \n",
      "[I 2025-12-02 21:18:43,763] Trial 21 finished with value: 0.7110873333678843 and parameters: {'learning_rate': 0.01000539062402839, 'feature_fraction': 0.7571610066136789, 'bagging_fraction': 0.9520907778264632, 'lambda_l1': 2.9052217952686395e-08, 'lambda_l2': 0.0012192000976449604, 'num_leaves': 23, 'max_depth': 5, 'min_data_in_leaf': 15, 'n_estimators': 1437}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:47,070] Trial 22 finished with value: 0.7079429807152655 and parameters: {'learning_rate': 0.01237417754267297, 'feature_fraction': 0.7617355055331593, 'bagging_fraction': 0.9359282255705716, 'lambda_l1': 4.054095363240381e-08, 'lambda_l2': 0.013417600908588434, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 16, 'n_estimators': 1170}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:49,162] Trial 23 finished with value: 0.7098261522653083 and parameters: {'learning_rate': 0.014210910602066742, 'feature_fraction': 0.7247624791176901, 'bagging_fraction': 0.9318323816655391, 'lambda_l1': 5.986986021636939e-08, 'lambda_l2': 0.04998760732586019, 'num_leaves': 31, 'max_depth': 4, 'min_data_in_leaf': 13, 'n_estimators': 1113}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:51,302] Trial 24 pruned. \n",
      "[I 2025-12-02 21:18:53,695] Trial 25 finished with value: 0.7092925010058347 and parameters: {'learning_rate': 0.01939774771227776, 'feature_fraction': 0.7715639198637909, 'bagging_fraction': 0.8838932754910213, 'lambda_l1': 5.6947943316397305e-08, 'lambda_l2': 3.3262266687137544e-05, 'num_leaves': 44, 'max_depth': 5, 'min_data_in_leaf': 16, 'n_estimators': 705}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:18:55,731] Trial 26 pruned. \n",
      "[I 2025-12-02 21:18:57,869] Trial 27 finished with value: 0.7081172082114944 and parameters: {'learning_rate': 0.012981366286568295, 'feature_fraction': 0.7524400444113912, 'bagging_fraction': 0.8308692373414474, 'lambda_l1': 9.90941876602003e-06, 'lambda_l2': 0.006612205689373621, 'num_leaves': 19, 'max_depth': 4, 'min_data_in_leaf': 11, 'n_estimators': 1110}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:19:02,607] Trial 28 finished with value: 0.7080026155806026 and parameters: {'learning_rate': 0.01596117644424243, 'feature_fraction': 0.8089367688030792, 'bagging_fraction': 0.975565250884611, 'lambda_l1': 9.791640312616621e-05, 'lambda_l2': 0.06452130251558956, 'num_leaves': 28, 'max_depth': 6, 'min_data_in_leaf': 16, 'n_estimators': 2195}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:19:03,005] Trial 29 pruned. \n",
      "[I 2025-12-02 21:19:04,001] Trial 30 pruned. \n",
      "[I 2025-12-02 21:19:06,147] Trial 31 pruned. \n",
      "[I 2025-12-02 21:19:11,725] Trial 32 finished with value: 0.7120025274494447 and parameters: {'learning_rate': 0.011929307564235412, 'feature_fraction': 0.8202597233550889, 'bagging_fraction': 0.9795677850194692, 'lambda_l1': 0.00011583093024220605, 'lambda_l2': 0.10003806040403121, 'num_leaves': 32, 'max_depth': 7, 'min_data_in_leaf': 16, 'n_estimators': 2085}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:19:13,811] Trial 33 pruned. \n",
      "[I 2025-12-02 21:19:15,331] Trial 34 pruned. \n",
      "[I 2025-12-02 21:19:19,697] Trial 35 finished with value: 0.7081514455695991 and parameters: {'learning_rate': 0.024187943437660026, 'feature_fraction': 0.8448925819256083, 'bagging_fraction': 0.9848523751314937, 'lambda_l1': 0.0801907347888313, 'lambda_l2': 0.0036905784671370213, 'num_leaves': 34, 'max_depth': 8, 'min_data_in_leaf': 17, 'n_estimators': 1504}. Best is trial 11 with value: 0.7051123913640143.\n",
      "[I 2025-12-02 21:19:20,670] Trial 36 pruned. \n",
      "[I 2025-12-02 21:19:22,265] Trial 37 pruned. \n",
      "[I 2025-12-02 21:19:25,041] Trial 38 pruned. \n",
      "[I 2025-12-02 21:19:25,691] Trial 39 pruned. \n",
      "[I 2025-12-02 21:19:27,002] Trial 40 pruned. \n",
      "[I 2025-12-02 21:19:28,136] Trial 41 pruned. \n",
      "[I 2025-12-02 21:19:29,023] Trial 42 pruned. \n",
      "[I 2025-12-02 21:19:30,063] Trial 43 pruned. \n",
      "[I 2025-12-02 21:19:30,933] Trial 44 pruned. \n",
      "[I 2025-12-02 21:19:32,567] Trial 45 pruned. \n",
      "[I 2025-12-02 21:19:33,420] Trial 46 pruned. \n",
      "[I 2025-12-02 21:19:33,790] Trial 47 pruned. \n",
      "[I 2025-12-02 21:19:35,795] Trial 48 pruned. \n",
      "[I 2025-12-02 21:19:38,160] Trial 49 finished with value: 0.70407152914453 and parameters: {'learning_rate': 0.010050802431942165, 'feature_fraction': 0.7419145275064326, 'bagging_fraction': 0.941348302398084, 'lambda_l1': 6.515031558069105e-08, 'lambda_l2': 1.2875767679925879e-05, 'num_leaves': 38, 'max_depth': 4, 'min_data_in_leaf': 17, 'n_estimators': 1377}. Best is trial 49 with value: 0.70407152914453.\n",
      "[I 2025-12-02 21:19:41,293] Trial 50 pruned. \n",
      "[I 2025-12-02 21:19:43,647] Trial 51 finished with value: 0.7050196996186547 and parameters: {'learning_rate': 0.011552259819126701, 'feature_fraction': 0.7458346452017997, 'bagging_fraction': 0.9441397289893794, 'lambda_l1': 1.1103661601386194e-08, 'lambda_l2': 5.499738345617985e-05, 'num_leaves': 34, 'max_depth': 4, 'min_data_in_leaf': 18, 'n_estimators': 1375}. Best is trial 49 with value: 0.70407152914453.\n",
      "[I 2025-12-02 21:19:45,100] Trial 52 pruned. \n",
      "[I 2025-12-02 21:19:47,501] Trial 53 finished with value: 0.700508704952909 and parameters: {'learning_rate': 0.011195037760469592, 'feature_fraction': 0.9859691186730863, 'bagging_fraction': 0.957976338847922, 'lambda_l1': 1.081745728010402e-08, 'lambda_l2': 8.793739904301527e-05, 'num_leaves': 34, 'max_depth': 4, 'min_data_in_leaf': 19, 'n_estimators': 1280}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:19:48,761] Trial 54 pruned. \n",
      "[I 2025-12-02 21:19:52,215] Trial 55 finished with value: 0.7072911600002726 and parameters: {'learning_rate': 0.011312063846743855, 'feature_fraction': 0.9036539154514283, 'bagging_fraction': 0.9114391796820489, 'lambda_l1': 7.785510570257714e-08, 'lambda_l2': 6.143766694015848e-06, 'num_leaves': 42, 'max_depth': 4, 'min_data_in_leaf': 18, 'n_estimators': 1588}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:19:54,596] Trial 56 pruned. \n",
      "[I 2025-12-02 21:19:55,634] Trial 57 pruned. \n",
      "[I 2025-12-02 21:19:57,217] Trial 58 pruned. \n",
      "[I 2025-12-02 21:19:58,030] Trial 59 pruned. \n",
      "[I 2025-12-02 21:20:00,518] Trial 60 finished with value: 0.7019360189171077 and parameters: {'learning_rate': 0.010195909083632961, 'feature_fraction': 0.9016280150216539, 'bagging_fraction': 0.9901568465123858, 'lambda_l1': 2.849872333196905e-08, 'lambda_l2': 6.291239887863793e-05, 'num_leaves': 55, 'max_depth': 4, 'min_data_in_leaf': 18, 'n_estimators': 1325}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:20:02,892] Trial 61 finished with value: 0.7013786480921597 and parameters: {'learning_rate': 0.010078039004590568, 'feature_fraction': 0.9117538485230603, 'bagging_fraction': 0.9838593068448258, 'lambda_l1': 3.8916282755420305e-08, 'lambda_l2': 7.939829455962279e-05, 'num_leaves': 55, 'max_depth': 4, 'min_data_in_leaf': 18, 'n_estimators': 1308}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:20:03,984] Trial 62 pruned. \n",
      "[I 2025-12-02 21:20:05,778] Trial 63 pruned. \n",
      "[I 2025-12-02 21:20:07,435] Trial 64 pruned. \n",
      "[I 2025-12-02 21:20:09,409] Trial 65 finished with value: 0.7048412389022468 and parameters: {'learning_rate': 0.014441901182940928, 'feature_fraction': 0.9174861634423245, 'bagging_fraction': 0.9548616440241909, 'lambda_l1': 4.938869825466808e-08, 'lambda_l2': 0.00012446053843160053, 'num_leaves': 57, 'max_depth': 4, 'min_data_in_leaf': 20, 'n_estimators': 1056}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:20:10,741] Trial 66 pruned. \n",
      "[I 2025-12-02 21:20:11,852] Trial 67 pruned. \n",
      "[I 2025-12-02 21:20:12,960] Trial 68 pruned. \n",
      "[I 2025-12-02 21:20:13,759] Trial 69 pruned. \n",
      "[I 2025-12-02 21:20:16,421] Trial 70 finished with value: 0.7074407927467936 and parameters: {'learning_rate': 0.012378497929669966, 'feature_fraction': 0.9338205232181149, 'bagging_fraction': 0.9927226653165695, 'lambda_l1': 1.2461020709533662e-06, 'lambda_l2': 0.0005664221740619595, 'num_leaves': 54, 'max_depth': 5, 'min_data_in_leaf': 17, 'n_estimators': 1134}. Best is trial 53 with value: 0.700508704952909.\n",
      "[I 2025-12-02 21:20:18,170] Trial 71 pruned. \n",
      "[I 2025-12-02 21:20:20,476] Trial 72 finished with value: 0.7003342502664132 and parameters: {'learning_rate': 0.010119557595927472, 'feature_fraction': 0.8794972491756733, 'bagging_fraction': 0.9251266037165474, 'lambda_l1': 2.315831682200497e-08, 'lambda_l2': 9.635134818231603e-05, 'num_leaves': 60, 'max_depth': 4, 'min_data_in_leaf': 20, 'n_estimators': 1256}. Best is trial 72 with value: 0.7003342502664132.\n",
      "[I 2025-12-02 21:20:21,305] Trial 73 pruned. \n",
      "[I 2025-12-02 21:20:23,255] Trial 74 finished with value: 0.6893607001651857 and parameters: {'learning_rate': 0.011552609520026576, 'feature_fraction': 0.8580945732187625, 'bagging_fraction': 0.9266415740122277, 'lambda_l1': 3.1982428566503605e-07, 'lambda_l2': 0.00012481658849905204, 'num_leaves': 64, 'max_depth': 3, 'min_data_in_leaf': 19, 'n_estimators': 1288}. Best is trial 74 with value: 0.6893607001651857.\n",
      "[I 2025-12-02 21:20:25,503] Trial 75 pruned. \n",
      "[I 2025-12-02 21:20:26,568] Trial 76 pruned. \n",
      "[I 2025-12-02 21:20:27,787] Trial 77 pruned. \n",
      "[I 2025-12-02 21:20:29,208] Trial 78 pruned. \n",
      "[I 2025-12-02 21:20:30,135] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plots/time_series_plot_rec.html\n"
     ]
    }
   ],
   "source": [
    "models = config['models']\n",
    "cv_config = config['modeling']['cv_config']\n",
    "methods = config['reconciliation']['methods']\n",
    "min_trace_methods = config['reconciliation']['min_trace_methods']\n",
    "mid_level = config['reconciliation']['middle_level']\n",
    "evaluation_path = config['paths']['evaluation']['evaluation_path']\n",
    "if os.path.exists(os.path.join(evaluation_path,'metrics_summary.csv')):\n",
    "    os.remove(os.path.join(evaluation_path,'metrics_summary.csv'))\n",
    "\n",
    "candidate_info = {}\n",
    "candidate_performances = {}\n",
    "for model in models:\n",
    "    is_enable = models[model]['enabled']\n",
    "    #check if model is enable in yaml file\n",
    "    if is_enable:\n",
    "        type_model = models[model]['type']\n",
    "        if type_model == 'mlforecast':\n",
    "            #Get Tuning info\n",
    "            model_name = models[model]['regressor']\n",
    "            fixed_params = models[model]['fixed_params']\n",
    "            param_space = config['parameter_space'][model]\n",
    "            mlforecast_params = config['modeling']['mlforecast']\n",
    "            training_metric = config['modeling']['training_metric']\n",
    "            compare_metrics = config['modeling']['compare_metrics']\n",
    "            #Tuning model\n",
    "            best_value,best_model_params,best_mlforecast_params,mlf_fit_params =\\\n",
    "                  ModelTuning(\n",
    "                                df=train,\n",
    "                                config=config,\n",
    "                                model_name=model_name,\n",
    "                                fixed_params=fixed_params,\n",
    "                                param_space=param_space,\n",
    "                                cv_config=cv_config,\n",
    "                                mlforecast_params=mlforecast_params,\n",
    "                                tuning_metric = training_metric\n",
    "                            ).run()\n",
    "            \n",
    "            #create model with best tuning parameters\n",
    "            candidate, fitted_values, metric,results_metrics = CreateCanditateModel(\n",
    "                                df=train,\n",
    "                                config=config,\n",
    "                                cv_config=cv_config,\n",
    "                                type_model=type_model,\n",
    "                                model_name=model_name,\n",
    "                                metric=best_value,\n",
    "                                cv_metric = training_metric,\n",
    "                                compare_metrics=compare_metrics,\n",
    "                                model_params=best_model_params,\n",
    "                                mlf_params=best_mlforecast_params,\n",
    "                                mlf_fit_params = mlf_fit_params\n",
    "                                ).run()\n",
    "        else:\n",
    "            #create model without tuning parameters\n",
    "            candidate, fitted_values, metric,results_metrics = CreateCanditateModel(\n",
    "                                df=train,\n",
    "                                config=config,\n",
    "                                cv_config=cv_config,\n",
    "                                type_model=type_model,\n",
    "                                compare_metrics=compare_metrics,\n",
    "                                model_name=model_name\n",
    "                                ).run()\n",
    "                \n",
    "        candidate_info.update({metric:candidate})\n",
    "        candidate_performances.update({model:results_metrics})\n",
    "\n",
    "        #eavluate model\n",
    "        prediction,validation_metric,results_metrics = ModelEvaluate(\n",
    "                                candidate_model=candidate,\n",
    "                                model_name=model_name,\n",
    "                                fitted_values=fitted_values,\n",
    "                                train=train,\n",
    "                                test=test,\n",
    "                                n_months_test=6,\n",
    "                                validation_metric='rmsse',\n",
    "                                compare_metrics=compare_metrics,\n",
    "                                config=config\n",
    "                                ).run()\n",
    "        \n",
    "        #HIerarchical Reconcilier\n",
    "        df_post_processed,methods = DatasetReconciliator(\n",
    "                        Y_df = Y_df,\n",
    "                        S_df = S_df,\n",
    "                        tags = tags,\n",
    "                        model_name = model_name,\n",
    "                        methods = methods,\n",
    "                        mid_level = mid_level,\n",
    "                        min_trace_methods = min_trace_methods,\n",
    "                        fitted_values = fitted_values,\n",
    "                        prediction = prediction\n",
    "                    ).run()\n",
    "        \n",
    "        CompareRecMethods(df_post_processed,methods,fitted_values,test,config).save_plot()\n",
    "        \n",
    "        for method in methods:\n",
    "            \n",
    "            df_rec_method = df_post_processed[['unique_id','ds',method]]\n",
    "            # Evaluate with each hierarchical reconcilier\n",
    "            prediction,validation_metric,results_metrics = ModelEvaluate(\n",
    "                                                                        model_name=method,\n",
    "                                                                        fitted_values=fitted_values,\n",
    "                                                                        train=train,\n",
    "                                                                        test=test,\n",
    "                                                                        n_months_test=6,\n",
    "                                                                        validation_metric='rmsse',\n",
    "                                                                        compare_metrics=compare_metrics,\n",
    "                                                                        config=config,\n",
    "                                                                        prediction = df_rec_method\n",
    "                                                                        ).run()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba8e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>wrmsse</th>\n",
       "      <th>smape</th>\n",
       "      <th>mase</th>\n",
       "      <th>rmsse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>234.863823</td>\n",
       "      <td>0.731466</td>\n",
       "      <td>0.772472</td>\n",
       "      <td>0.304561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cv_results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>235.046468</td>\n",
       "      <td>1.071921</td>\n",
       "      <td>1.194544</td>\n",
       "      <td>0.289716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMRegressor/TopDown_method-forecast_proportions</td>\n",
       "      <td>86.599236</td>\n",
       "      <td>0.611330</td>\n",
       "      <td>0.652742</td>\n",
       "      <td>0.238016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor/MiddleOut_middle_level-total/pro...</td>\n",
       "      <td>267.077531</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.915773</td>\n",
       "      <td>0.282179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMRegressor/MinTrace_method-wls_var</td>\n",
       "      <td>503.152315</td>\n",
       "      <td>1.059725</td>\n",
       "      <td>1.178678</td>\n",
       "      <td>0.289347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBMRegressor/MinTrace_method-wls_struct</td>\n",
       "      <td>265.995224</td>\n",
       "      <td>1.335695</td>\n",
       "      <td>1.572913</td>\n",
       "      <td>0.487975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMRegressor/MinTrace_method-mint_shrink</td>\n",
       "      <td>433.077938</td>\n",
       "      <td>2.029097</td>\n",
       "      <td>2.355311</td>\n",
       "      <td>0.450594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>final_model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model      wrmsse     smape  \\\n",
       "0                                      LGBMRegressor  234.863823  0.731466   \n",
       "1                                      LGBMRegressor  235.046468  1.071921   \n",
       "2  LGBMRegressor/TopDown_method-forecast_proportions   86.599236  0.611330   \n",
       "3  LGBMRegressor/MiddleOut_middle_level-total/pro...  267.077531  0.831800   \n",
       "4              LGBMRegressor/MinTrace_method-wls_var  503.152315  1.059725   \n",
       "5           LGBMRegressor/MinTrace_method-wls_struct  265.995224  1.335695   \n",
       "6          LGBMRegressor/MinTrace_method-mint_shrink  433.077938  2.029097   \n",
       "\n",
       "       mase     rmsse  rmse        notes  \n",
       "0  0.772472  0.304561   0.0   cv_results  \n",
       "1  1.194544  0.289716   0.0  final_model  \n",
       "2  0.652742  0.238016   0.0  final_model  \n",
       "3  0.915773  0.282179   0.0  final_model  \n",
       "4  1.178678  0.289347   0.0  final_model  \n",
       "5  1.572913  0.487975   0.0  final_model  \n",
       "6  2.355311  0.450594   0.0  final_model  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('evaluation/metrics_summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "or-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
